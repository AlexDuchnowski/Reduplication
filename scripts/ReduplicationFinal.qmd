---
title: "ReduplicationFinal"
format: html
editor: visual
---

## Data

```{r}
salad.data <- read.csv("../data/salad_consolidated_refined_counted.csv")

head(salad.data)
```
```{r}
opensubs.data <- read.csv("../data/222k_filtered_counted.csv")

head(opensubs.data)
```

```{r}
# Load required libraries
library(dplyr)

# Read the CSV file
data <- read.csv("../data/222k_filtered_counted.csv")

# Read the labels from text files
labels_1 <- readLines("../data/annotations/opensubs_agreed_1.txt")
labels_2 <- readLines("../data/annotations/opensubs_agreed_2.txt")

# Combine the labels into a single vector
all_labels <- c(labels_1, labels_2)

# Add the labels as a new column to the data frame
#data <- mutate(data, Label = all_labels)

# Write the updated data frame to a new CSV file
#write.csv(data, "222k_filtered_counted_with_labels.csv", row.names = FALSE)


```

```{r}
library(ggplot2)

ggplot(salad.data, aes(x = POS, fill = POS)) +
  geom_bar() +
  geom_text(stat='count', aes(label= after_stat(count)), vjust=-0.5) + 
  labs(title = "Distribution of Parts of Speech",
       x = "Part of Speech",
       y = "Count")

```

```{r}
library(ggplot2)

ggplot(salad.data, aes(x = Label, fill = Label)) +
  geom_bar() +
  geom_text(stat='count', aes(label= after_stat(count)), vjust=-0.5) + 
  labs(title = "Distribution of Semantic Contributions",
       x = "Semantic Contribution",
       y = "Count")

```

```{r}
library(ggplot2)
library(nnet)

summary(salad.data)
ggplot(salad.data, aes(x = POS, fill = Label)) +
  geom_bar() + 
  labs(title = "Distribution of Semantic Contributions by POS",
       x = "POS",
       y = "Count")


```

```{r}

```

## Model

```{r}
model <- multinom(Label ~ POS + Word_Length + Freq_Count, data = salad.data)

summary(model)
```
```{r}
z <- summary(model)$coefficients/summary(model)$standard.errors
z
```
```{r}
p <- (1 - pnorm(abs(z), 0, 1)) * 2
p
```
```{r}
length.model <- multinom(Label ~ Word_Length, data = salad.data)

summary(length.model)
```
```{r}
# Load required libraries
library(ggplot2)
library(tidyr)

# Generate data for prediction (word length)
new_data <- data.frame(Word_Length = seq(min(salad.data$Word_Length), max(salad.data$Word_Length), length.out = 100))
head(new_data)
```

```{r}
# Predict probabilities for each category
predictions <- predict(length.model, newdata = new_data, type = "probs")
head(predictions)
```

```{r}
# Convert predictions to a data frame
predictions_df <- data.frame(new_data, predictions)

# Reshape predictions for plotting
predictions_df <- gather(predictions_df, Label, Probability, -Word_Length)

# Plot predicted probabilities
ggplot(predictions_df, aes(x = Word_Length, y = Probability, color = Label)) +
  geom_line() +
  labs(title = "Likelihood of Semantic Contribution Label by Word Length",
       x = "Word Length",
       y = "Predicted Probability",
       color = "Semantic Contribution Label") +
  theme_minimal()
```
```{r}
freq.model <- multinom(Label ~ Freq_Count, data = salad.data)

summary(freq.model)
```
```{r}
# Load required libraries
library(ggplot2)
library(tidyr)

# Generate data for prediction (word length)
new_data <- data.frame(Freq_Count = seq(min(salad.data$Freq_Count), max(salad.data$Freq_Count), length.out = 100))
head(new_data)
```

```{r}
# Predict probabilities for each category
predictions <- predict(freq.model, newdata = new_data, type = "probs")

head(predictions)
```

```{r}
# Load required libraries
library(ggplot2)
library(tidyr)

# Generate data for prediction (word length)
new_data <- data.frame(Freq_Count = seq(min(salad.data$Freq_Count), max(salad.data$Freq_Count), length.out = 100))

# Predict probabilities for each category
predictions <- predict(freq.model, newdata = new_data, type = "probs")

# Convert predictions to a data frame
predictions_df <- data.frame(new_data, predictions)

# Reshape predictions for plotting
predictions_df <- gather(predictions_df, Label, Probability, -Freq_Count)

# Plot predicted probabilities
ggplot(predictions_df, aes(x = Freq_Count, y = Probability, color = Label)) +
  geom_line() +
  labs(title = "Likelihood of Semantic Contribution Label by Frequency",
       x = "Frequency",
       y = "Predicted Probability",
       color = "Semantic Contribution Label") +
  theme_minimal()
```


```{r}
head(pp <- fitted(model), n=20)

```
Values repeat by POS, so extracting one example of each will give us the probability of having a certain semantic contribution given POS.

Example 1: NN, Example 2: JJ, Example 6: RB, Example 15: VB

```{r}
library(tibble)

(my_tibble <- tibble(
  Part.of.Speech = c("NN", "JJ", "RB", "VB"),
  E = c(0.07946939, 0.42028842, 0.19230901, 0.14705943),
  P = c(0.7019874, 0.5072467, 0.3461578, 0.6176449),
  S = c(0.21854326, 0.07246485, 0.46153322, 0.23529567)
))

```


